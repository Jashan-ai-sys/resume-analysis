{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2827d8d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Phase 3] Data file: C:\\Users\\WIN11\\OneDrive\\Desktop\\resume proj\\projwithml\\data\\final_merged_iob_dataset.json\n",
      "[Phase 3] Output dir: C:\\Users\\WIN11\\OneDrive\\Desktop\\resume proj\\projwithml\\phase3\\ner-bert-output\n",
      "[Phase 3] Loading dataset...\n",
      "[Phase 3] Total samples loaded: 116805\n",
      "[Phase 3] Columns: ['tokens', 'labels', '_orig_idx']\n",
      "[Phase 3] Sampled size (pre-split): 60000\n",
      "[Phase 3] Train: 54000 | Eval: 6000\n",
      "[Phase 3] Loading model from: C:\\\\Users\\\\WIN11\\\\OneDrive\\\\Desktop\\\\resume proj\\\\projwithml\\\\phase2\\\\phase2_ner_model\n",
      "[Phase 3] Labels (7): ['B-COMPANY', 'B-ROLE', 'B-SKILL', 'I-COMPANY', 'I-ROLE', 'I-SKILL', 'O']\n",
      "[Phase 3] Tokenizing train...\n",
      "[Phase 3] Tokenizing eval...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\WIN11\\AppData\\Local\\Temp\\ipykernel_10308\\3333019195.py:277: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Phase 3] Starting training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10125' max='10125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10125/10125 2:37:23, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000673</td>\n",
       "      <td>0.999001</td>\n",
       "      <td>0.999445</td>\n",
       "      <td>0.999222</td>\n",
       "      <td>0.999882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000845</td>\n",
       "      <td>0.998114</td>\n",
       "      <td>0.999333</td>\n",
       "      <td>0.998723</td>\n",
       "      <td>0.999830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.999889</td>\n",
       "      <td>0.999944</td>\n",
       "      <td>0.999917</td>\n",
       "      <td>0.999987</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Phase 3] Evaluating...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='375' max='375' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [375/375 01:41]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Phase 3] Eval metrics: {\n",
      "  \"eval_loss\": 1.6940721252467483e-05,\n",
      "  \"eval_precision\": 0.9998889074043215,\n",
      "  \"eval_recall\": 0.9999444506165982,\n",
      "  \"eval_f1\": 0.9999166782391333,\n",
      "  \"eval_accuracy\": 0.9999869166459514,\n",
      "  \"eval_runtime\": 102.2422,\n",
      "  \"eval_samples_per_second\": 58.684,\n",
      "  \"eval_steps_per_second\": 3.668,\n",
      "  \"epoch\": 3.0\n",
      "}\n",
      "[Phase 3] Saving model to: C:\\Users\\WIN11\\OneDrive\\Desktop\\resume proj\\projwithml\\phase3\\ner-bert-output\n",
      "[Phase 3] Done.\n"
     ]
    }
   ],
   "source": [
    "# phase3_train_ready.py\n",
    "\n",
    "from __future__ import annotations\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import random\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Optional, List, Dict\n",
    "\n",
    "import numpy as np\n",
    "from datasets import load_dataset, Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForTokenClassification,\n",
    "    DataCollatorForTokenClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    set_seed,\n",
    ")\n",
    "\n",
    "# --- Metrics: prefer seqeval, fallback to token accuracy only ---\n",
    "_SEQEVAL_OK = True\n",
    "try:\n",
    "    from seqeval.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "except Exception:\n",
    "    _SEQEVAL_OK = False\n",
    "    precision_score = recall_score = f1_score = accuracy_score = None\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Config and env helpers\n",
    "# ----------------------------\n",
    "@dataclass\n",
    "class Args:\n",
    "    # Data\n",
    "    data_file: Optional[str] = None       # If None, auto-discover in ../data/phase3\n",
    "    tokens_field: str = \"tokens\"\n",
    "    tags_field: str = \"labels\"            # Your dataset uses 'labels'\n",
    "    sample_size: int = 60000              # target sample size\n",
    "    eval_test_size: float = 0.1           # 10% eval from the sampled pool\n",
    "    seed: int = 42\n",
    "\n",
    "    # Model/checkpoint\n",
    "    model_name_or_path: str = \"C:/Users/WIN11/OneDrive/Desktop/resume proj/projwithml/phase2/phase2_ner_model\"  # resumes from Phase 2 by default\n",
    "    output_dir: str = \"C:/Users/WIN11/OneDrive/Desktop/resume proj/projwithml/phase3/ner-bert-output\"           # default Phase 3 output\n",
    "\n",
    "    # Tokenization/training\n",
    "    max_length: int = 256\n",
    "    learning_rate: float = 5e-5\n",
    "    weight_decay: float = 0.01\n",
    "    warmup_ratio: float = 0.1\n",
    "    num_train_epochs: int = 3\n",
    "    per_device_train_batch_size: int = 16\n",
    "    per_device_eval_batch_size: int = 16\n",
    "    gradient_accumulation_steps: int = 1\n",
    "    logging_steps: int = 100\n",
    "\n",
    "\n",
    "def is_notebook() -> bool:\n",
    "    return \"ipykernel\" in sys.modules or \"IPython\" in sys.modules\n",
    "\n",
    "\n",
    "def discover_data_file() -> Optional[str]:\n",
    "    # 1) env override\n",
    "    env_path = os.environ.get(\"PHASE3_DATA_FILE\")\n",
    "    if env_path and Path(env_path).is_file():\n",
    "        return env_path\n",
    "\n",
    "    # 2) common project locations relative to this script\n",
    "    here = Path(__file__).resolve().parent if \"__file__\" in globals() else Path.cwd()\n",
    "    candidates = [\n",
    "        here / \"../data/phase3\",\n",
    "        here / \"../../data/phase3\",\n",
    "        here / \"data/phase3\",\n",
    "    ]\n",
    "    exts = (\".json\", \".jsonl\")\n",
    "    for root in candidates:\n",
    "        if root.exists():\n",
    "            files = [p for p in root.rglob(\"*\") if p.suffix.lower() in exts]\n",
    "            if files:\n",
    "                # pick the first deterministically\n",
    "                return str(sorted(files)[0])\n",
    "    return None\n",
    "\n",
    "\n",
    "def load_model_and_labels(model_path: str):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path, use_fast=True)\n",
    "    model = AutoModelForTokenClassification.from_pretrained(model_path)\n",
    "\n",
    "    # Normalize id2label/label2id\n",
    "    id2label_raw = model.config.id2label\n",
    "    if isinstance(id2label_raw, dict):\n",
    "        id2label = {int(k): v for k, v in id2label_raw.items()}\n",
    "    else:\n",
    "        id2label = {i: v for i, v in enumerate(id2label_raw)}\n",
    "    label2id = {v: k for k, v in id2label.items()}\n",
    "\n",
    "    # Persist normalized mappings on config\n",
    "    model.config.id2label = id2label\n",
    "    model.config.label2id = label2id\n",
    "    return tokenizer, model, id2label, label2id\n",
    "\n",
    "\n",
    "def align_labels_with_tokens(labels, word_ids):\n",
    "    aligned = []\n",
    "    prev_word = None\n",
    "    for wid in word_ids:\n",
    "        if wid is None:\n",
    "            aligned.append(-100)\n",
    "        elif wid != prev_word:\n",
    "            aligned.append(labels[wid])\n",
    "        else:\n",
    "            aligned.append(-100)\n",
    "        prev_word = wid\n",
    "    return aligned\n",
    "\n",
    "\n",
    "def compute_metrics_builder(id2label: Dict[int, str]):\n",
    "    if _SEQEVAL_OK:\n",
    "        def compute_metrics(p):\n",
    "            preds = np.argmax(p.predictions, axis=-1)\n",
    "            labels = p.label_ids\n",
    "            true_labels, true_preds = [], []\n",
    "            for pred, lab in zip(preds, labels):\n",
    "                mask = lab != -100\n",
    "                tl = [id2label[int(l)] for l in lab[mask]]\n",
    "                tp = [id2label[int(p_)] for p_ in pred[mask]]\n",
    "                true_labels.append(tl)\n",
    "                true_preds.append(tp)\n",
    "            return {\n",
    "                \"precision\": precision_score(true_labels, true_preds),\n",
    "                \"recall\":    recall_score(true_labels, true_preds),\n",
    "                \"f1\":        f1_score(true_labels, true_preds),\n",
    "                \"accuracy\":  accuracy_score(true_labels, true_preds),\n",
    "            }\n",
    "        return compute_metrics\n",
    "    else:\n",
    "        # Fallback: token-level accuracy only (no seqeval installed)\n",
    "        def compute_metrics(p):\n",
    "            preds = np.argmax(p.predictions, axis=-1)\n",
    "            labels = p.label_ids\n",
    "            correct, total = 0, 0\n",
    "            for pred, lab in zip(preds, labels):\n",
    "                for p_i, l_i in zip(pred, lab):\n",
    "                    if l_i == -100:\n",
    "                        continue\n",
    "                    total += 1\n",
    "                    correct += int(p_i == l_i)\n",
    "            acc = correct / total if total else 0.0\n",
    "            return {\"accuracy_token\": acc}\n",
    "        return compute_metrics\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Main training flow\n",
    "# ----------------------------\n",
    "def run_phase3(args: Args):\n",
    "    # Resolve data path\n",
    "    data_path = args.data_file or discover_data_file()\n",
    "    if not data_path or not Path(data_path).is_file():\n",
    "        raise FileNotFoundError(\n",
    "            \"Could not find data file. Set Args.data_file to your JSON/JSONL path \"\n",
    "            \"or place a file under ../data/phase3.\"\n",
    "        )\n",
    "\n",
    "    # Prepare output\n",
    "    out_dir = Path(args.output_dir).resolve()\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Reproducibility\n",
    "    set_seed(args.seed)\n",
    "    random.seed(args.seed)\n",
    "    np.random.seed(args.seed)\n",
    "\n",
    "    print(f\"[Phase 3] Data file: {data_path}\")\n",
    "    print(f\"[Phase 3] Output dir: {out_dir}\")\n",
    "    print(f\"[Phase 3] Loading dataset...\")\n",
    "    raw = load_dataset(\"json\", data_files={\"raw\": data_path})[\"raw\"]\n",
    "    raw = raw.add_column(\"_orig_idx\", list(range(len(raw))))\n",
    "    print(f\"[Phase 3] Total samples loaded: {len(raw)}\")\n",
    "    print(f\"[Phase 3] Columns: {raw.column_names}\")\n",
    "\n",
    "    # Shuffle + sample 60k (or less if not enough)\n",
    "    raw_shuffled = raw.shuffle(seed=args.seed)\n",
    "    k = min(args.sample_size, len(raw_shuffled))\n",
    "    sampled = raw_shuffled.select(range(k))\n",
    "    print(f\"[Phase 3] Sampled size (pre-split): {len(sampled)}\")\n",
    "\n",
    "    # Split into train/eval\n",
    "    split = sampled.train_test_split(test_size=args.eval_test_size, seed=args.seed)\n",
    "    train_ds, eval_ds = split[\"train\"], split[\"test\"]\n",
    "    print(f\"[Phase 3] Train: {len(train_ds)} | Eval: {len(eval_ds)}\")\n",
    "\n",
    "    # Load model + tokenizer from Phase 2 checkpoint (default)\n",
    "    print(f\"[Phase 3] Loading model from: {args.model_name_or_path}\")\n",
    "    tokenizer, model, id2label, label2id = load_model_and_labels(args.model_name_or_path)\n",
    "    num_labels = len(id2label)\n",
    "    print(f\"[Phase 3] Labels ({num_labels}): {sorted(label2id.keys())}\")\n",
    "\n",
    "    # Detect if dataset labels are ints or strings\n",
    "    sample_tags = train_ds[0][args.tags_field]\n",
    "    labels_are_int = isinstance(sample_tags[0], int)\n",
    "\n",
    "    def to_label_ids(tag_seq):\n",
    "        if labels_are_int:\n",
    "            # Ensure within range\n",
    "            bad = [t for t in tag_seq if not (0 <= int(t) < num_labels)]\n",
    "            if bad:\n",
    "                raise ValueError(f\"Found out-of-range label ids {bad}; expected 0..{num_labels-1}\")\n",
    "            return [int(t) for t in tag_seq]\n",
    "        else:\n",
    "            try:\n",
    "                return [int(label2id[t]) for t in tag_seq]\n",
    "            except KeyError as e:\n",
    "                known = sorted(label2id.keys())\n",
    "                raise KeyError(f\"Unknown label '{e.args[0]}'. Known labels: {known}\") from e\n",
    "\n",
    "    # Tokenization + alignment\n",
    "    def tokenize_and_align(batch):\n",
    "        tokens_batch = batch[args.tokens_field]\n",
    "        tags_batch = batch[args.tags_field]\n",
    "        tag_ids_batch = [to_label_ids(tags) for tags in tags_batch]\n",
    "\n",
    "        enc = tokenizer(\n",
    "            tokens_batch,\n",
    "            is_split_into_words=True,\n",
    "            truncation=True,\n",
    "            max_length=args.max_length,\n",
    "            return_offsets_mapping=False,\n",
    "        )\n",
    "\n",
    "        aligned = []\n",
    "        for i, tags in enumerate(tag_ids_batch):\n",
    "            word_ids = enc.word_ids(batch_index=i)\n",
    "            aligned.append(align_labels_with_tokens(tags, word_ids))\n",
    "\n",
    "        enc[\"labels\"] = aligned\n",
    "        return enc\n",
    "\n",
    "    # Keep minimal original columns\n",
    "    cols_keep = (args.tokens_field, args.tags_field, \"_orig_idx\")\n",
    "    rem_train = [c for c in train_ds.column_names if c not in cols_keep]\n",
    "    rem_eval  = [c for c in eval_ds.column_names if c not in cols_keep]\n",
    "\n",
    "    print(\"[Phase 3] Tokenizing train...\")\n",
    "    train_tok = train_ds.map(tokenize_and_align, batched=True, remove_columns=rem_train, desc=\"Tokenize train\")\n",
    "    print(\"[Phase 3] Tokenizing eval...\")\n",
    "    eval_tok  = eval_ds.map(tokenize_and_align,  batched=True, remove_columns=rem_eval,  desc=\"Tokenize eval\")\n",
    "\n",
    "    # Data collator + metrics\n",
    "    data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)\n",
    "    compute_metrics = compute_metrics_builder(id2label)\n",
    "\n",
    "    # Training arguments\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=str(out_dir),\n",
    "        learning_rate=args.learning_rate,\n",
    "        weight_decay=args.weight_decay,\n",
    "        warmup_ratio=args.warmup_ratio,\n",
    "        num_train_epochs=args.num_train_epochs,\n",
    "        per_device_train_batch_size=args.per_device_train_batch_size,\n",
    "        per_device_eval_batch_size=args.per_device_eval_batch_size,\n",
    "        gradient_accumulation_steps=args.gradient_accumulation_steps,\n",
    "        eval_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        save_total_limit=2,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"f1\" if _SEQEVAL_OK else \"accuracy_token\",\n",
    "        greater_is_better=True,\n",
    "        logging_steps=args.logging_steps,\n",
    "        report_to=\"none\",\n",
    "        seed=args.seed,\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_tok,\n",
    "        eval_dataset=eval_tok,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "\n",
    "    # Train + evaluate\n",
    "    print(\"[Phase 3] Starting training...\")\n",
    "    trainer.train()\n",
    "    print(\"[Phase 3] Evaluating...\")\n",
    "    metrics = trainer.evaluate()\n",
    "    print(\"[Phase 3] Eval metrics:\", json.dumps({k: float(v) for k, v in metrics.items() if isinstance(v, (int, float))}, indent=2))\n",
    "\n",
    "    # Save model + tokenizer\n",
    "    print(f\"[Phase 3] Saving model to: {out_dir}\")\n",
    "    trainer.save_model(str(out_dir))\n",
    "    tokenizer.save_pretrained(str(out_dir))\n",
    "\n",
    "    # Save split traceability\n",
    "    split_info = {\n",
    "        \"seed\": args.seed,\n",
    "        \"data_file\": data_path,\n",
    "        \"total_full\": int(len(raw)),\n",
    "        \"sampled_k\": int(k),\n",
    "        \"train_ratio\": 1.0 - args.eval_test_size,\n",
    "        \"train_orig_indices\": [int(i) for i in train_ds[\"_orig_idx\"]],\n",
    "        \"eval_orig_indices\": [int(i) for i in eval_ds[\"_orig_idx\"]],\n",
    "        \"labels_from_checkpoint\": sorted(label2id.keys()),\n",
    "        \"model_loaded_from\": args.model_name_or_path,\n",
    "    }\n",
    "    with open(out_dir / \"phase3_split_info.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(split_info, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "    print(\"[Phase 3] Done.\")\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Entrypoint (works in notebook and CLI)\n",
    "# ----------------------------\n",
    "def main():\n",
    "    # Notebook-friendly: no argparse needed. CLI can still override via env.\n",
    "    a = Args()\n",
    "    # Optional: set explicit paths here if you want to hardcode them:\n",
    "    a.data_file = r\"C:\\Users\\WIN11\\OneDrive\\Desktop\\resume proj\\projwithml\\data\\final_merged_iob_dataset.json\"\n",
    "    a.model_name_or_path = r\"C:\\\\Users\\\\WIN11\\\\OneDrive\\\\Desktop\\\\resume proj\\\\projwithml\\\\phase2\\\\phase2_ner_model\"\n",
    "\n",
    "    a.output_dir = r\"C:\\Users\\WIN11\\OneDrive\\Desktop\\resume proj\\projwithml\\phase3\\ner-bert-output\"\n",
    "\n",
    "    # If running as CLI and you want explicit args, uncomment and use argparse:\n",
    "    # if not is_notebook():\n",
    "    #     import argparse\n",
    "    #     p = argparse.ArgumentParser()\n",
    "    #     p.add_argument(\"--data_file\", required=False)\n",
    "    #     p.add_argument(\"--model_name_or_path\", default=a.model_name_or_path)\n",
    "    #     p.add_argument(\"--output_dir\", default=a.output_dir)\n",
    "    #     ns = p.parse_args()\n",
    "    #     if ns.data_file: a.data_file = ns.data_file\n",
    "    #     a.model_name_or_path = ns.model_name_or_path\n",
    "    #     a.output_dir = ns.output_dir\n",
    "\n",
    "    run_phase3(a)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "854786d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\WIN11\\OneDrive\\Desktop\\resume proj\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Sample 1]\n",
      "Text: John Doe is a Senior Software Engineer at Google with expertise in Python and Machine Learning.\n",
      "Filtered Entities (COMPANY, ROLE, SKILL only):\n",
      "  - Senior Software Engineer (ROLE | score: 1.000)\n",
      "  - Google (COMPANY | score: 1.000)\n",
      "  - Python (SKILL | score: 1.000)\n",
      "  - Machine Learning (SKILL | score: 1.000)\n",
      "\n",
      "[Sample 2]\n",
      "Text: Jane Smith completed her Master's in Data Science from Stanford University in 2020.\n",
      "Filtered Entities (COMPANY, ROLE, SKILL only):\n",
      "  - Master ' s (ROLE | score: 0.937)\n",
      "  - Data Science (ROLE | score: 0.760)\n",
      "  - Stanford University (COMPANY | score: 0.974)\n",
      "  - 2020 (COMPANY | score: 0.638)\n",
      "\n",
      "[Sample 3]\n",
      "Text: Rahul Verma worked as a Data Analyst at Deloitte and has experience with SQL, Tableau, and Excel.\n",
      "Filtered Entities (COMPANY, ROLE, SKILL only):\n",
      "  - V (ROLE | score: 0.418)\n",
      "  - Data Analyst (ROLE | score: 1.000)\n",
      "  - Deloitte (COMPANY | score: 0.999)\n",
      "  - SQL (SKILL | score: 0.997)\n",
      "  - , Tableau, (COMPANY | score: 0.989)\n",
      "  - Excel (COMPANY | score: 1.000)\n",
      "\n",
      "[Sample 4]\n",
      "Text: Priya Mehta holds a Bachelor's degree in Computer Engineering from IIT Bombay.\n",
      "Filtered Entities (COMPANY, ROLE, SKILL only):\n",
      "  - Me (COMPANY | score: 0.556)\n",
      "  - Bachelor ' s degree in Computer (ROLE | score: 0.999)\n",
      "  - Engineering (SKILL | score: 1.000)\n",
      "  - IIT Bombay (COMPANY | score: 1.000)\n",
      "\n",
      "[Sample 5]\n",
      "Text: Amit Sharma is currently employed at Infosys as a Cloud Solutions Architect.\n",
      "Filtered Entities (COMPANY, ROLE, SKILL only):\n",
      "  - ##it Sharma (COMPANY | score: 0.646)\n",
      "  - Infosys (COMPANY | score: 0.999)\n",
      "  - Cloud Solutions Architect (ROLE | score: 1.000)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline\n",
    "import pandas as pd\n",
    "\n",
    "# --- Config ---\n",
    "MODEL_PATH = \"C:/Users/WIN11/OneDrive/Desktop/resume proj/projwithml/phase3/ner-bert-output\"\n",
    "\n",
    "# --- Load tokenizer and model ---\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
    "model = AutoModelForTokenClassification.from_pretrained(MODEL_PATH)\n",
    "\n",
    "# --- Inference pipeline ---\n",
    "ner_pipeline = pipeline(\"ner\", model=model, tokenizer=tokenizer, aggregation_strategy=\"simple\")\n",
    "\n",
    "# --- Resume-style sample data ---\n",
    "sample_texts = [\n",
    "    \"John Doe is a Senior Software Engineer at Google with expertise in Python and Machine Learning.\",\n",
    "    \"Jane Smith completed her Master's in Data Science from Stanford University in 2020.\",\n",
    "    \"Rahul Verma worked as a Data Analyst at Deloitte and has experience with SQL, Tableau, and Excel.\",\n",
    "    \"Priya Mehta holds a Bachelor's degree in Computer Engineering from IIT Bombay.\",\n",
    "    \"Amit Sharma is currently employed at Infosys as a Cloud Solutions Architect.\"\n",
    "]\n",
    "\n",
    "df = pd.DataFrame({\"text\": sample_texts})\n",
    "\n",
    "# --- Run predictions ---\n",
    "results_all = []\n",
    "results_filtered = []\n",
    "\n",
    "ALLOWED_LABELS = [\"COMPANY\", \"ROLE\", \"SKILL\"]  # Only keep these\n",
    "\n",
    "for text in sample_texts:\n",
    "    prediction = ner_pipeline(text)\n",
    "    results_all.append(prediction)\n",
    "    filtered = [ent for ent in prediction if ent[\"entity_group\"] in ALLOWED_LABELS]\n",
    "    results_filtered.append(filtered)\n",
    "\n",
    "# --- Diagnostics: output comparison ---\n",
    "for idx, (text, res) in enumerate(zip(sample_texts, results_filtered)):\n",
    "    if res:  # Only print samples that have COMPANY/ROLE/SKILL\n",
    "        print(f\"\\n[Sample {idx+1}]\")\n",
    "        print(\"Text:\", text)\n",
    "        print(\"Filtered Entities (COMPANY, ROLE, SKILL only):\")\n",
    "        for entity in res:\n",
    "            print(f\"  - {entity['word']} ({entity['entity_group']} | score: {entity['score']:.3f})\")\n",
    "\n",
    "# --- Save results ---\n",
    "df[\"predicted_entities_all\"] = results_all\n",
    "df[\"predicted_entities_filtered\"] = results_filtered\n",
    "df.to_csv(\"ner_resume_output_filtered.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abdca1de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Sample 1]\n",
      "Text: John Doe is a Senior Software Engineer at Google with expertise in Python and Machine Learning.\n",
      "Cleaned Entities (COMPANY, ROLE, SKILL only):\n",
      "  - Senior Software Engineer (ROLE | score: 1.000)\n",
      "  - Google (COMPANY | score: 1.000)\n",
      "  - Python (SKILL | score: 1.000)\n",
      "  - Machine Learning (SKILL | score: 1.000)\n",
      "\n",
      "[Sample 2]\n",
      "Text: Jane Smith completed her Master's in Data Science from Stanford University in 2020.\n",
      "Cleaned Entities (COMPANY, ROLE, SKILL only):\n",
      "  - Data Science (ROLE | score: 0.760)\n",
      "  - Stanford University (COMPANY | score: 0.974)\n",
      "  - 2020 (COMPANY | score: 0.638)\n",
      "\n",
      "[Sample 3]\n",
      "Text: Rahul Verma worked as a Data Analyst at Deloitte and has experience with SQL, Tableau, and Excel.\n",
      "Cleaned Entities (COMPANY, ROLE, SKILL only):\n",
      "  - Data Analyst (ROLE | score: 1.000)\n",
      "  - Deloitte (COMPANY | score: 0.999)\n",
      "  - SQL (SKILL | score: 0.997)\n",
      "  - Tableau (COMPANY | score: 0.989)\n",
      "  - Excel (COMPANY | score: 1.000)\n",
      "\n",
      "[Sample 4]\n",
      "Text: Priya Mehta holds a Bachelor's degree in Computer Engineering from IIT Bombay.\n",
      "Cleaned Entities (COMPANY, ROLE, SKILL only):\n",
      "  - Me (COMPANY | score: 0.556)\n",
      "  - Engineering (SKILL | score: 1.000)\n",
      "\n",
      "[Sample 5]\n",
      "Text: Amit Sharma is currently employed at Infosys as a Cloud Solutions Architect.\n",
      "Cleaned Entities (COMPANY, ROLE, SKILL only):\n",
      "  - it Sharma (COMPANY | score: 0.646)\n",
      "  - Infosys (COMPANY | score: 0.999)\n",
      "  - Cloud Solutions Architect (ROLE | score: 1.000)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline\n",
    "import pandas as pd\n",
    "\n",
    "# --- Config ---\n",
    "MODEL_PATH = r\"C:/Users/WIN11/OneDrive/Desktop/resume proj/projwithml/phase 3/ner-bert-output\"\n",
    "\n",
    "# --- Load tokenizer and model ---\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
    "model = AutoModelForTokenClassification.from_pretrained(MODEL_PATH)\n",
    "\n",
    "# --- Inference pipeline ---\n",
    "ner_pipeline = pipeline(\"ner\", model=model, tokenizer=tokenizer, aggregation_strategy=\"simple\")\n",
    "\n",
    "# --- Post-processing helper ---\n",
    "def clean_entities(entities):\n",
    "    CLEANED = []\n",
    "    degree_keywords = {\n",
    "        \"bachelor\", \"master\", \"mba\", \"phd\", \"m.sc\", \"b.sc\",\n",
    "        \"msc\", \"bsc\", \"degree\", \"diploma\", \"btech\", \"mtech\"\n",
    "    }\n",
    "    \n",
    "    for ent in entities:\n",
    "        label = ent[\"entity_group\"].upper()\n",
    "        word = ent[\"word\"].strip()\n",
    "        \n",
    "        if label not in {\"COMPANY\", \"ROLE\", \"SKILL\"}:\n",
    "            continue\n",
    "        if word.startswith(\"##\"):\n",
    "            word = word[2:]\n",
    "        if len(word) == 1 and word.lower() != \"c\":\n",
    "            continue\n",
    "        if any(k in word.lower() for k in degree_keywords):\n",
    "            continue\n",
    "        \n",
    "        word = word.strip(\",. \")\n",
    "        if not word:\n",
    "            continue\n",
    "        \n",
    "        CLEANED.append({\n",
    "            \"word\": word,\n",
    "            \"entity_group\": label,\n",
    "            \"score\": ent[\"score\"]\n",
    "        })\n",
    "    \n",
    "    return CLEANED\n",
    "\n",
    "# --- Resume-style sample data ---\n",
    "sample_texts = [\n",
    "    \"John Doe is a Senior Software Engineer at Google with expertise in Python and Machine Learning.\",\n",
    "    \"Jane Smith completed her Master's in Data Science from Stanford University in 2020.\",\n",
    "    \"Rahul Verma worked as a Data Analyst at Deloitte and has experience with SQL, Tableau, and Excel.\",\n",
    "    \"Priya Mehta holds a Bachelor's degree in Computer Engineering from IIT Bombay.\",\n",
    "    \"Amit Sharma is currently employed at Infosys as a Cloud Solutions Architect.\"\n",
    "]\n",
    "\n",
    "df = pd.DataFrame({\"text\": sample_texts})\n",
    "\n",
    "# --- Run predictions ---\n",
    "results_all = []\n",
    "results_filtered = []\n",
    "\n",
    "for text in sample_texts:\n",
    "    prediction = ner_pipeline(text)\n",
    "    results_all.append(prediction)\n",
    "    filtered = clean_entities(prediction)\n",
    "    results_filtered.append(filtered)\n",
    "\n",
    "# --- Display results inline in Jupyter ---\n",
    "for idx, (text, res) in enumerate(zip(sample_texts, results_filtered)):\n",
    "    if res:\n",
    "        print(f\"\\n[Sample {idx+1}]\")\n",
    "        print(\"Text:\", text)\n",
    "        print(\"Cleaned Entities (COMPANY, ROLE, SKILL only):\")\n",
    "        for entity in res:\n",
    "            print(f\"  - {entity['word']} ({entity['entity_group']} | score: {entity['score']:.3f})\")\n",
    "\n",
    "# Optional: save cleaned results\n",
    "df[\"predicted_entities_all\"] = results_all\n",
    "df[\"predicted_entities_cleaned\"] = results_filtered\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb74d781",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "from fastapi import FastAPI\n",
    "from pydantic import BaseModel\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "MODEL_PATH = r\"C:/Users/WIN11/OneDrive/Desktop/resume proj/projwithml/phase 3/ner-bert-output\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH, local_files_only=True)\n",
    "model = AutoModelForTokenClassification.from_pretrained(MODEL_PATH, local_files_only=True)\n",
    "ner_pipeline = pipeline(\"ner\", model=model, tokenizer=tokenizer, aggregation_strategy=\"simple\")\n",
    "\n",
    "def clean_entities(entities):\n",
    "    CLEANED = []\n",
    "    degree_keywords = {\"bachelor\", \"master\", \"mba\", \"phd\", \"m.sc\", \"b.sc\", \"msc\", \"bsc\", \"degree\", \"diploma\", \"btech\", \"mtech\"}\n",
    "    for ent in entities:\n",
    "        label = ent[\"entity_group\"].upper()\n",
    "        word = ent[\"word\"].strip()\n",
    "        if label not in {\"COMPANY\", \"ROLE\", \"SKILL\"}:\n",
    "            continue\n",
    "        if word.startswith(\"##\"):\n",
    "            word = word[2:]\n",
    "        if len(word) == 1 and word.lower() != \"c\":\n",
    "            continue\n",
    "        if any(k in word.lower() for k in degree_keywords):\n",
    "            continue\n",
    "        word = word.strip(\",. \")\n",
    "        if not word:\n",
    "            continue\n",
    "        CLEANED.append({\n",
    "            \"word\": word,\n",
    "            \"entity_group\": label,\n",
    "            \"score\": ent[\"score\"]\n",
    "        })\n",
    "    return CLEANED\n",
    "\n",
    "class TextInput(BaseModel):\n",
    "    text: str\n",
    "\n",
    "@app.post(\"/extract_entities\")\n",
    "def extract_entities(data: TextInput):\n",
    "    prediction = ner_pipeline(data.text)\n",
    "    cleaned = clean_entities(prediction)\n",
    "    return {\"entities\": cleaned}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
