{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8bf21f10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Skill requirement dataset generated: skill_requirement_dataset.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# =========================\n",
    "# Role → Skill Templates (All roles covered, 10–15 realistic 2025 skills each)\n",
    "# =========================\n",
    "role_skill_templates = {\n",
    "    \"Software Engineer\": [\n",
    "        \"Java\", \"C++\", \"Python\", \"System Design\", \"Databases\", \"APIs\", \n",
    "        \"Data Structures\", \"Algorithms\", \"Git\", \"Linux\", \"Testing\", \n",
    "        \"Debugging\", \"Cloud Deployment\", \"OOP\", \"Agile\"\n",
    "    ],\n",
    "    \"Backend Developer\": [\n",
    "        \"Java\", \"Spring Boot\", \"SQL\", \"Docker\", \"Microservices\", \"APIs\", \n",
    "        \"Python\", \"System Design\", \"NoSQL (MongoDB)\", \"GraphQL\", \"Scalability\",\n",
    "        \"Kafka\", \"Redis\", \"CI/CD\", \"Cloud Platforms\"\n",
    "    ],\n",
    "    \"Frontend Developer\": [\n",
    "        \"React\", \"JavaScript\", \"HTML/CSS\", \"TypeScript\", \"Next.js\", \n",
    "        \"Tailwind CSS\", \"Redux\", \"GraphQL\", \"REST APIs\", \"UI Testing\", \n",
    "        \"Accessibility\", \"Figma Integration\", \"Webpack\", \"Performance Optimization\", \"Responsive Design\"\n",
    "    ],\n",
    "    \"Full Stack Developer\": [\n",
    "        \"JavaScript\", \"TypeScript\", \"React\", \"Node.js\", \"Express\", \"MongoDB\", \n",
    "        \"SQL\", \"GraphQL\", \"REST APIs\", \"Docker\", \"Kubernetes\", \"Git\", \n",
    "        \"CI/CD\", \"Cloud Deployment\", \"Testing\"\n",
    "    ],\n",
    "    \"Data Scientist\": [\n",
    "        \"Python\", \"SQL\", \"Machine Learning\", \"Deep Learning\", \"TensorFlow\", \n",
    "        \"PyTorch\", \"Statistics\", \"Data Visualization\", \"Feature Engineering\", \n",
    "        \"Pandas\", \"Numpy\", \"Model Deployment\", \"Spark\", \"A/B Testing\", \"Data Cleaning\"\n",
    "    ],\n",
    "    \"Data Engineer\": [\n",
    "        \"SQL\", \"ETL Pipelines\", \"Big Data\", \"Apache Spark\", \"Hadoop\", \"Python\", \n",
    "        \"Data Warehousing\", \"Airflow\", \"Cloud Data Platforms\", \"Kafka\", \n",
    "        \"Database Design\", \"Data Modeling\", \"Snowflake\", \"Batch Processing\", \"Streaming Systems\"\n",
    "    ],\n",
    "    \"Data Analyst\": [\n",
    "        \"SQL\", \"Excel\", \"Power BI\", \"Tableau\", \"Python\", \"Data Visualization\", \n",
    "        \"Statistics\", \"Data Cleaning\", \"Reporting\", \"A/B Testing\", \n",
    "        \"Requirement Gathering\", \"ETL\", \"Business Communication\", \"Agile\", \"Presentation Skills\"\n",
    "    ],\n",
    "    \"AI/ML Engineer\": [\n",
    "        \"Python\", \"PyTorch\", \"TensorFlow\", \"Transformers\", \"LLMs\", \"NLP\", \n",
    "        \"Computer Vision\", \"Reinforcement Learning\", \"MLOps\", \"Docker\", \n",
    "        \"Kubernetes\", \"LangChain\", \"Vector Databases\", \"Prompt Engineering\", \"CUDA\"\n",
    "    ],\n",
    "    \"Generative AI Engineer\": [\n",
    "        \"Python\", \"PyTorch\", \"TensorFlow\", \"LLMs\", \"LangChain\", \"Prompt Engineering\", \n",
    "        \"Vector Databases\", \"RAG Pipelines\", \"Fine-tuning\", \"Hugging Face\", \n",
    "        \"Transformers\", \"MLOps\", \"Cloud AI APIs\", \"Data Preprocessing\", \"AI Ethics\"\n",
    "    ],\n",
    "    \"Cloud Engineer\": [\n",
    "        \"AWS\", \"Azure\", \"Google Cloud\", \"Kubernetes\", \"Docker\", \"Terraform\", \n",
    "        \"CI/CD\", \"Networking\", \"Linux\", \"Monitoring\", \"Cloud Security\", \n",
    "        \"Serverless\", \"Load Balancing\", \"Identity Management\", \"DevOps\"\n",
    "    ],\n",
    "    \"DevOps Engineer\": [\n",
    "        \"Docker\", \"Kubernetes\", \"Jenkins\", \"Terraform\", \"CI/CD\", \"Ansible\", \n",
    "        \"Linux\", \"Cloud Platforms (AWS/Azure/GCP)\", \"Prometheus\", \n",
    "        \"Scripting (Bash/Python)\", \"Networking\", \"Agile\", \"Git\", \n",
    "        \"Load Balancing\", \"Security\"\n",
    "    ],\n",
    "    \"Cybersecurity Engineer\": [\n",
    "        \"Penetration Testing\", \"Threat Modeling\", \"SIEM\", \"Firewalls\", \n",
    "        \"Cloud Security\", \"Network Security\", \"Incident Response\", \"Cryptography\", \n",
    "        \"Vulnerability Assessment\", \"Risk Management\", \"IDS/IPS\", \"Ethical Hacking\", \n",
    "        \"Zero Trust\", \"Compliance\", \"Secure Coding\"\n",
    "    ],\n",
    "    \"Site Reliability Engineer (SRE)\": [\n",
    "        \"Linux\", \"Prometheus\", \"Cloud Platforms\", \"CI/CD\", \n",
    "        \"Incident Management\", \"Automation\", \"Python\", \"Go\", \"Scalability\", \n",
    "        \"Disaster Recovery\", \"Networking\", \"System Design\", \"Logging\", \"Load Balancing\", \"Kubernetes\"\n",
    "    ],\n",
    "    \"Mobile App Developer\": [\n",
    "        \"Kotlin\", \"Swift\", \"Flutter\", \"React Native\", \"Firebase\", \"REST APIs\", \n",
    "        \"Android SDK\", \"iOS Development\", \"UI/UX for Mobile\", \"Testing\", \n",
    "        \"Push Notifications\", \"GraphQL\", \"App Store Deployment\", \"Version Control\", \"Agile\"\n",
    "    ],\n",
    "    \"UI/UX Designer\": [\n",
    "        \"Figma\", \"Adobe XD\", \"Wireframing\", \"Prototyping\", \"User Research\", \n",
    "        \"Design Thinking\", \"Sketch\", \"Usability Testing\", \"Responsive Design\", \n",
    "        \"Accessibility\", \"Illustrator\", \"Interaction Design\", \n",
    "        \"Storyboarding\", \"Visual Design\", \"Branding\"\n",
    "    ],\n",
    "    \"QA Engineer\": [\n",
    "        \"Selenium\", \"Automation Testing\", \"JUnit\", \"Manual Testing\", \"Bug Tracking\", \n",
    "        \"Performance Testing\", \"Load Testing\", \"API Testing\", \"Test Planning\", \n",
    "        \"Regression Testing\", \"Test Automation Frameworks\", \"CI/CD\", \"Agile QA\", \"Postman\", \"Cypress\"\n",
    "    ],\n",
    "    \"Business Analyst\": [\n",
    "        \"SQL\", \"Excel\", \"Power BI\", \"Tableau\", \"Python (basic)\", \"Data Visualization\", \n",
    "        \"Requirement Gathering\", \"Client Communication\", \"Domain Knowledge\", \n",
    "        \"Statistics\", \"Business Process Modeling\", \"ETL\", \"Reporting\", \"Agile\", \"Presentation Skills\"\n",
    "    ],\n",
    "    \"Product Manager\": [\n",
    "        \"Agile\", \"Scrum\", \"Roadmap Planning\", \"User Research\", \"Wireframing\", \n",
    "        \"Stakeholder Management\", \"Market Research\", \"Analytics\", \"Communication\", \n",
    "        \"Prioritization\", \"Prototyping\", \"KPI Tracking\", \"Product Strategy\", \"UI/UX Collaboration\", \"A/B Testing\"\n",
    "    ],\n",
    "    \"Database Administrator\": [\n",
    "        \"SQL\", \"Oracle DB\", \"MySQL\", \"PostgreSQL\", \"Database Tuning\", \n",
    "        \"Backup & Recovery\", \"Replication\", \"Security\", \"NoSQL\", \n",
    "        \"MongoDB\", \"Data Modeling\", \"Query Optimization\", \"Stored Procedures\", \"Cloud Databases\", \"Performance Tuning\"\n",
    "    ],\n",
    "    \"Hardware Engineer\": [\n",
    "        \"VLSI\", \"Verilog\", \"SystemVerilog\", \"Embedded Systems\", \n",
    "        \"Microcontrollers\", \"FPGA\", \"PCB Design\", \"Signal Processing\", \n",
    "        \"Circuits\", \"Hardware Testing\", \"Simulation Tools\", \"Digital Electronics\", \n",
    "        \"Analog Design\", \"System Architecture\", \"Low-Power Design\"\n",
    "    ],\n",
    "    \"Network Engineer\": [\n",
    "        \"Networking Protocols\", \"Routing & Switching\", \"Firewalls\", \"Load Balancing\", \n",
    "        \"VPN\", \"LAN/WAN\", \"Cisco Technologies\", \"Wireshark\", \"Network Monitoring\", \n",
    "        \"Cloud Networking\", \"Security\", \"BGP/OSPF\", \"SD-WAN\", \"Network Automation\", \"Troubleshooting\"\n",
    "    ],\n",
    "    \"Research Scientist\": [\n",
    "        \"Deep Learning\", \"NLP\", \"Reinforcement Learning\", \"Generative AI\", \n",
    "        \"Mathematics\", \"Python\", \"PyTorch\", \"TensorFlow\", \"Research Papers\", \n",
    "        \"Experimentation\", \"Model Evaluation\", \"CUDA\", \"Statistics\", \n",
    "        \"Graph Neural Networks\", \"Knowledge Graphs\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# =========================\n",
    "# Company → Role mapping (same as before)\n",
    "# =========================\n",
    "# (reuse your companies dictionary here)\n",
    "\n",
    "# =========================\n",
    "# Build Skill Dataset\n",
    "# =========================\n",
    "skill_dataset = {}\n",
    "for company, roles in companies.items():\n",
    "    skill_dataset[company] = {}\n",
    "    for role in roles:\n",
    "        # always get skills, fallback to [\"TBD\"] instead of []\n",
    "        skill_dataset[company][role] = role_skill_templates.get(role, [\"TBD\"])\n",
    "\n",
    "# =========================\n",
    "# Save as JSON\n",
    "# =========================\n",
    "with open(\"skill_requirement_dataset.json\", \"w\") as f:\n",
    "    json.dump(skill_dataset, f, indent=2)\n",
    "\n",
    "print(\"✅ Skill requirement dataset generated: skill_requirement_dataset.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e37af4ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Generated 3762 training and 418 validation samples.\n",
      "ℹ️ Perfect: 805, Partial: 2785, Weak: 590\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "\n",
    "# Input: your current skill dictionary (we’ll extend it here)\n",
    "skill_dict_file = \"C:/Users/WIN11/Intelligent-Resume-Feedback-System/data/skill_requirement_dataset.json\"\n",
    "\n",
    "# Output files\n",
    "train_out = \"C:/Users/WIN11/Intelligent-Resume-Feedback-System/data/train_T5.jsonl\"\n",
    "valid_out = \"C:/Users/WIN11/Intelligent-Resume-Feedback-System/data/valid_T5.jsonl\"\n",
    "\n",
    "# Feedback templates\n",
    "start_templates = [\n",
    "    \"Strong base with {skills}.\",\n",
    "    \"You already have good expertise in {skills}.\",\n",
    "    \"Good foundation in {skills}.\",\n",
    "    \"Solid background covering {skills}.\",\n",
    "    \"Your experience with {skills} is impressive.\"\n",
    "]\n",
    "\n",
    "missing_templates = [\n",
    "    \" Still missing {missing}, which are important for this role.\",\n",
    "    \" You could improve in {missing} to be a stronger match.\",\n",
    "    \" Consider strengthening {missing} for better fit.\",\n",
    "    \" To increase chances, add {missing}.\",\n",
    "    \" It would help to work on {missing}.\"\n",
    "]\n",
    "\n",
    "match_templates = [\n",
    "    \" You meet around {percent}% of the requirements.\",\n",
    "    \" This puts you at roughly {percent}% match.\",\n",
    "    \" Overall match is about {percent}%.\",\n",
    "    \" Estimated fit: {percent}%.\",\n",
    "    \" Your profile aligns {percent}% with the role.\"\n",
    "]\n",
    "\n",
    "# Perfect match templates\n",
    "perfect_match_templates = [\n",
    "    \"Excellent! Your skills {skills} fully match the requirements for the {role} role at {company}. 🎉 This is a perfect 100% match.\",\n",
    "    \"Outstanding! With {skills}, you meet every requirement for the {role} position at {company}. Perfect fit!\",\n",
    "    \"Perfect alignment — your experience in {skills} matches all expectations for a {role} at {company}.\",\n",
    "    \"You have all the required skills ({skills}) for the {role} role at {company}. This is a complete match (100%).\"\n",
    "]\n",
    "\n",
    "# Weak profile templates\n",
    "weak_templates = [\n",
    "    \"Your current skills {skills} cover only a small part of the requirements for {role} at {company}. Major gaps remain: {missing}.\",\n",
    "    \"Limited match: with only {skills}, you miss critical skills such as {missing}.\",\n",
    "    \"Weak profile for {role} — key gaps are {missing}. Strong improvement needed.\",\n",
    "    \"You only cover {skills}, but most required skills ({missing}) are missing. Very low match.\"\n",
    "]\n",
    "\n",
    "def generate_feedback(company, role, required_skills, candidate_skills, mode=\"partial\"):\n",
    "    missing = [s for s in required_skills if s not in candidate_skills]\n",
    "    percent = int((len(candidate_skills) / len(required_skills)) * 100)\n",
    "\n",
    "    if mode == \"perfect\":\n",
    "        feedback = random.choice(perfect_match_templates).format(\n",
    "            skills=\", \".join(required_skills), role=role, company=company\n",
    "        )\n",
    "        candidate_skills = required_skills[:]\n",
    "    elif mode == \"weak\":\n",
    "        feedback = random.choice(weak_templates).format(\n",
    "            skills=\", \".join(candidate_skills), role=role, company=company, missing=\", \".join(missing)\n",
    "        )\n",
    "    else:  # partial\n",
    "        start = random.choice(start_templates).format(skills=\", \".join(candidate_skills))\n",
    "        miss = random.choice(missing_templates).format(missing=\", \".join(missing))\n",
    "        match = random.choice(match_templates).format(percent=percent)\n",
    "        feedback = start + miss + match\n",
    "    \n",
    "    return {\n",
    "        \"input\": f\"Company: {company} | Role: {role} | Candidate Skills: {', '.join(candidate_skills)}\",\n",
    "        \"output\": feedback\n",
    "    }\n",
    "\n",
    "def expand_dataset(skill_dict_file, train_out, valid_out, target_size=6000, valid_ratio=0.1, ratios=(0.2, 0.65, 0.15)):\n",
    "    # Load skill dict\n",
    "    with open(skill_dict_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        skill_dataset = json.load(f)\n",
    "\n",
    "    # Extend with more Indian dream companies\n",
    "    extra_companies = {\n",
    "        \"Infosys\": {\n",
    "            \"Software Engineer\": [\"Java\", \"Spring Boot\", \"Microservices\", \"SQL\", \"REST APIs\", \"Cloud\", \"Data Structures\", \"Problem Solving\", \"Git\", \"Agile\"],\n",
    "            \"Data Engineer\": [\"Python\", \"SQL\", \"ETL\", \"Spark\", \"Hadoop\", \"Kafka\", \"AWS\", \"Data Warehousing\", \"Airflow\", \"Linux\"]\n",
    "        },\n",
    "        \"TCS\": {\n",
    "            \"System Engineer\": [\"Java\", \"C#\", \"SQL\", \"HTML/CSS\", \"JavaScript\", \"Spring Boot\", \"React\", \"Angular\", \"Agile\", \"Git\"],\n",
    "            \"Business Analyst\": [\"Excel\", \"SQL\", \"Requirement Gathering\", \"UML\", \"Communication Skills\", \"JIRA\", \"Agile\", \"Data Visualization\"]\n",
    "        },\n",
    "        \"Wipro\": {\n",
    "            \"Cloud Engineer\": [\"Azure\", \"AWS\", \"Linux\", \"Terraform\", \"Docker\", \"Kubernetes\", \"CI/CD\", \"Networking\", \"Security\", \"Scripting\"]\n",
    "        },\n",
    "        \"Accenture\": {\n",
    "            \"AI Engineer\": [\"Python\", \"TensorFlow\", \"PyTorch\", \"Machine Learning\", \"Deep Learning\", \"NLP\", \"SQL\", \"Data Visualization\", \"Cloud\", \"Docker\"]\n",
    "        },\n",
    "        \"Deloitte\": {\n",
    "            \"Consultant\": [\"Excel\", \"SQL\", \"Power BI\", \"Presentation Skills\", \"Business Analysis\", \"Finance Domain\", \"Communication Skills\", \"Agile\", \"Problem Solving\"]\n",
    "        },\n",
    "        \"Adobe\": {\n",
    "            \"Frontend Developer\": [\"JavaScript\", \"React\", \"TypeScript\", \"HTML\", \"CSS\", \"Redux\", \"GraphQL\", \"Webpack\", \"Testing\", \"Agile\"]\n",
    "        },\n",
    "        \"Atlassian\": {\n",
    "            \"Backend Developer\": [\"Java\", \"Spring Boot\", \"Microservices\", \"SQL\", \"Kafka\", \"Docker\", \"Kubernetes\", \"REST APIs\", \"AWS\", \"Problem Solving\"]\n",
    "        },\n",
    "        \"Oracle\": {\n",
    "            \"Database Administrator\": [\"Oracle DB\", \"SQL\", \"PL/SQL\", \"Backup & Recovery\", \"Performance Tuning\", \"Linux\", \"Shell Scripting\", \"Data Security\", \"Cloud\", \"Monitoring\"]\n",
    "        },\n",
    "        \"IBM\": {\n",
    "            \"Cybersecurity Analyst\": [\"Networking\", \"Linux\", \"Firewalls\", \"IDS/IPS\", \"SIEM\", \"Python\", \"Threat Analysis\", \"Incident Response\", \"Cloud Security\", \"Compliance\"]\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Merge\n",
    "    for c, roles in extra_companies.items():\n",
    "        if c not in skill_dataset:\n",
    "            skill_dataset[c] = {}\n",
    "        skill_dataset[c].update(roles)\n",
    "\n",
    "    # Generate\n",
    "    examples = []\n",
    "    total_perfect, total_partial, total_weak = 0, 0, 0\n",
    "    for company, roles in skill_dataset.items():\n",
    "        for role, required_skills in roles.items():\n",
    "            if not required_skills or required_skills == [\"TBD\"]:\n",
    "                continue\n",
    "\n",
    "            for _ in range(20):  # candidate profiles per role\n",
    "                rand_val = random.random()\n",
    "                if rand_val < ratios[0]:  # perfect\n",
    "                    examples.append(generate_feedback(company, role, required_skills, required_skills, \"perfect\"))\n",
    "                    total_perfect += 1\n",
    "                elif rand_val < ratios[0] + ratios[1]:  # partial\n",
    "                    k = random.randint(2, max(2, len(required_skills)-1))\n",
    "                    candidate_skills = random.sample(required_skills, k=k)\n",
    "                    examples.append(generate_feedback(company, role, required_skills, candidate_skills, \"partial\"))\n",
    "                    total_partial += 1\n",
    "                else:  # weak\n",
    "                    candidate_skills = random.sample(required_skills, k=1)\n",
    "                    examples.append(generate_feedback(company, role, required_skills, candidate_skills, \"weak\"))\n",
    "                    total_weak += 1\n",
    "\n",
    "    # Shuffle\n",
    "    random.shuffle(examples)\n",
    "\n",
    "    # Train/valid split\n",
    "    split = int(len(examples) * (1 - valid_ratio))\n",
    "    train_examples = examples[:split]\n",
    "    valid_examples = examples[split:]\n",
    "\n",
    "    # Save\n",
    "    with open(train_out, \"w\", encoding=\"utf-8\") as f:\n",
    "        for ex in train_examples[:target_size]:\n",
    "            f.write(json.dumps(ex, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "    with open(valid_out, \"w\", encoding=\"utf-8\") as f:\n",
    "        for ex in valid_examples[: int(target_size * valid_ratio)]:\n",
    "            f.write(json.dumps(ex, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "    print(f\"✅ Generated {len(train_examples[:target_size])} training and {len(valid_examples[:int(target_size * valid_ratio)])} validation samples.\")\n",
    "    print(f\"ℹ️ Perfect: {total_perfect}, Partial: {total_partial}, Weak: {total_weak}\")\n",
    "\n",
    "# Run it\n",
    "expand_dataset(skill_dict_file, train_out, valid_out, target_size=6000)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
