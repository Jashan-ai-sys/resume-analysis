{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91ef0458",
   "metadata": {
    "tags": [
     "training t5 model"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\WIN11\\AppData\\Local\\Temp\\ipykernel_30508\\2320645591.py:135: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1180' max='1180' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1180/1180 44:59, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.669300</td>\n",
       "      <td>0.413191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.360400</td>\n",
       "      <td>0.262749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.293000</td>\n",
       "      <td>0.219035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.255500</td>\n",
       "      <td>0.198700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.242800</td>\n",
       "      <td>0.192850</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight', 'lm_head.weight'].\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='418' max='418' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [418/418 00:23]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Final Evaluation Metrics: {'eval_loss': 0.19284331798553467, 'eval_runtime': 23.5935, 'eval_samples_per_second': 17.717, 'eval_steps_per_second': 17.717, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./t5_skill_feedback\\\\tokenizer_config.json',\n",
       " './t5_skill_feedback\\\\special_tokens_map.json',\n",
       " './t5_skill_feedback\\\\tokenizer.json')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    T5ForConditionalGeneration,\n",
    "    T5TokenizerFast,\n",
    "    DataCollatorForSeq2Seq,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    EarlyStoppingCallback,\n",
    ")\n",
    "from evaluate import load\n",
    "\n",
    "# ✅ Settings\n",
    "model_name = \"t5-small\"   # try \"flan-t5-base\" if outputs collapse\n",
    "train_file = \"C:/Users/WIN11/Intelligent-Resume-Feedback-System/data/train_T5.jsonl\"\n",
    "valid_file = \"C:/Users/WIN11/Intelligent-Resume-Feedback-System/data/valid_T5.jsonl\"\n",
    "output_dir = \"./t5_skill_feedback\"\n",
    "\n",
    "# ✅ Training hyperparameters\n",
    "epochs = 5\n",
    "batch_size = 4\n",
    "grad_accum = 4\n",
    "lr = 3e-4\n",
    "weight_decay = 0.01\n",
    "warmup_ratio = 0.06\n",
    "patience = 3\n",
    "seed = 42\n",
    "fp16 = True\n",
    "gradient_checkpointing = True\n",
    "eval_every_steps = 500\n",
    "save_total_limit = 2\n",
    "logging_steps = 50\n",
    "\n",
    "\n",
    "# 1) Load tokenizer & model\n",
    "tokenizer = T5TokenizerFast.from_pretrained(model_name)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "if gradient_checkpointing:\n",
    "    model.gradient_checkpointing_enable()\n",
    "\n",
    "# 2) Load dataset\n",
    "dataset = load_dataset(\n",
    "    \"json\",\n",
    "    data_files={\"train\": train_file, \"validation\": valid_file}\n",
    ")\n",
    "\n",
    "# 3) Preprocess\n",
    "def preprocess(examples):\n",
    "    model_inputs = tokenizer(\n",
    "        examples[\"input\"],\n",
    "        max_length=max_input_len,\n",
    "        truncation=True\n",
    "    )\n",
    "    labels = tokenizer(\n",
    "        examples[\"output\"],\n",
    "        max_length=max_target_len,\n",
    "        truncation=True\n",
    "    )\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "tokenized = dataset.map(\n",
    "    preprocess,\n",
    "    batched=True,\n",
    "    remove_columns=dataset[\"train\"].column_names\n",
    ")\n",
    "\n",
    "# 4) Data collator\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)\n",
    "\n",
    "# 5) Metrics\n",
    "rouge = load(\"rouge\")\n",
    "bleu = load(\"bleu\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    # Compute ROUGE + BLEU\n",
    "    rouge_result = rouge.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    bleu_result = bleu.compute(predictions=[p.split() for p in decoded_preds],\n",
    "                               references=[[l.split()] for l in decoded_labels])\n",
    "\n",
    "    # 🔎 Show a live sample after each eval\n",
    "    print(\"\\n--- Live Sample ---\")\n",
    "    sample_input = \"Company: Google | Role: Data Scientist | Candidate Skills: Python, SQL, Pandas\"\n",
    "    inputs = tokenizer(sample_input, return_tensors=\"pt\").to(model.device)\n",
    "    outputs = model.generate(**inputs, max_length=max_target_len)\n",
    "    print(\"INPUT:\", sample_input)\n",
    "    print(\"OUTPUT:\", tokenizer.decode(outputs[0], skip_special_tokens=True))\n",
    "    print(\"--------------------\\n\")\n",
    "\n",
    "    return {\n",
    "        \"rouge1\": rouge_result[\"rouge1\"],\n",
    "        \"rougeL\": rouge_result[\"rougeL\"],\n",
    "        \"bleu\": bleu_result[\"bleu\"]\n",
    "    }\n",
    "\n",
    "# 6) Training arguments\n",
    "from transformers import TrainingArguments, Trainer, EarlyStoppingCallback\n",
    "\n",
    "# ✅ Optimized Training Arguments for 4GB GPU\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    eval_strategy=\"epoch\",          # evaluate once per epoch\n",
    "    save_strategy=\"epoch\",                # save best checkpoint per epoch\n",
    "    save_total_limit=2,                   # keep last 2 checkpoints only\n",
    "    learning_rate=lr,\n",
    "    num_train_epochs=epochs,\n",
    "    per_device_train_batch_size=4,        # smaller batch to fit VRAM\n",
    "    per_device_eval_batch_size=1,         # eval one sample at a time\n",
    "    gradient_accumulation_steps=4,        # simulate effective batch=16\n",
    "    weight_decay=weight_decay,\n",
    "    warmup_ratio=warmup_ratio,\n",
    "    logging_steps=logging_steps,\n",
    "    load_best_model_at_end=True,\n",
    "    report_to=[\"none\"],                   # or [\"tensorboard\"] if needed\n",
    "    seed=seed,\n",
    "    fp16=True,                            # mixed precision = less VRAM\n",
    "    fp16_full_eval=True,                  # mixed precision for eval too\n",
    "    dataloader_num_workers=0,             # reduce extra memory threads\n",
    ")\n",
    "\n",
    "# ✅ Early stopping (optional)\n",
    "callbacks = []\n",
    "if patience > 0:\n",
    "    callbacks.append(EarlyStoppingCallback(early_stopping_patience=patience))\n",
    "\n",
    "# ✅ Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized[\"train\"],\n",
    "    eval_dataset=tokenized[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    callbacks=callbacks,\n",
    ")\n",
    "\n",
    "# 🚀 Train\n",
    "trainer.train()\n",
    "\n",
    "# ✅ After training, display validation results\n",
    "metrics = trainer.evaluate()\n",
    "print(\"\\n📊 Final Evaluation Metrics:\", metrics)\n",
    "\n",
    "# Save model\n",
    "trainer.save_model(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce31163",
   "metadata": {
    "tags": [
     "testing"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔎 Testing Fine-Tuned Model\n",
      "\n",
      "Input: Company: Google | Role: Data Scientist | Candidate Skills: Python, SQL, Pandas\n",
      "Output: Strong base with Python, SQL, Pandas. It would help to work on SQL, Machine Learning, Deep Learning, TensorFlow, PyTorch, Statistics, Data Visualization, Feature Engineering, Pandas, Numpy, Model Deployment, Spark, A/B Testing, Data Cleaning. Your profile aligns 13% with the role.\n",
      "--------------------------------------------------------------------------------\n",
      "Input: Company: Microsoft | Role: Backend Developer | Candidate Skills: Python, Django, SQL\n",
      "Output: Strong base with Python, Django, SQL. It would help to work on Java, Spring Boot, SQL, Docker, Microservices, APIs, Python, System Design, NoSQL (MongoDB), GraphQL, Scalability, Kafka, Redis, CI/CD, Cloud Platforms. Your profile aligns 13% with the role.\n",
      "--------------------------------------------------------------------------------\n",
      "Input: Company: Accenture | Role: Data Scientist | Candidate Skills: Numpy, TensorFlow, SQL, Pandas, Deep Learning\n",
      "Output: Strong base with Numpy, TensorFlow, SQL, Pandas, Deep Learning. Consider strengthening Python, SQL, Machine Learning, PyTorch, Statistics, Data Visualization, Feature Engineering, Pandas, Model Deployment, Spark, A/B Testing for better fit. Your profile aligns 40% with the role.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import T5ForConditionalGeneration, T5TokenizerFast\n",
    "\n",
    "# ✅ Load fine-tuned model + tokenizer\n",
    "model_path = \"./t5_skill_feedback\"   # change if saved elsewhere\n",
    "tokenizer = T5TokenizerFast.from_pretrained(model_path)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_path)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# ✅ Function for inference\n",
    "def generate_feedback(input_text, max_length=128):\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\").to(device)\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_length=max_length,\n",
    "        num_beams=4,           # beam search for better text\n",
    "        early_stopping=True\n",
    "    )\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "# ✅ Test samples\n",
    "samples = [\n",
    "    \"Company: Google | Role: Data Scientist | Candidate Skills: Python, SQL, Pandas\",\n",
    "    \"Company: Microsoft | Role: Backend Developer | Candidate Skills: Python, Django, SQL\",\n",
    "    \"Company: Accenture | Role: Data Scientist | Candidate Skills: Numpy, TensorFlow, SQL, Pandas, Deep Learning\"\n",
    "]\n",
    "\n",
    "print(\"\\n🔎 Testing Fine-Tuned Model\\n\")\n",
    "for s in samples:\n",
    "    print(\"Input:\", s)\n",
    "    print(\"Output:\", generate_feedback(s))\n",
    "    print(\"-\" * 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e51fe56b",
   "metadata": {
    "tags": [
     "post processing "
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 Input: Google | Data Scientist | ['Python', 'SQL', 'Pandas']\n",
      "📝 Raw Model Output: You already have good expertise in Python, SQL, Pandas. It would help to work on SQL, Machine Learning, Deep Learning, TensorFlow, PyTorch, Statistics, Data Visualization, Feature Engineering, Pandas, Numpy, Model Deployment, Spark, A/B Testing, Data Cleaning. You meet around 26% of the requirements.\n",
      "✅ Final Feedback:\n",
      " ✅ You already have Python, SQL, Pandas.\n",
      "📌 To improve your profile for Data Scientist, focus on learning: Machine Learning, Deep Learning, TensorFlow, PyTorch, Statistics, Data Visualization, Feature Engineering, Numpy, Model Deployment, Spark, A/B Testing, Data Cleaning.\n",
      "📊 Profile Match: 20.0%\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "🔹 Input: Microsoft | Backend Developer | ['Python', 'Django', 'SQL']\n",
      "📝 Raw Model Output: You already have good expertise in Python, Django, SQL. It would help to work on Java, Spring Boot, SQL, Docker, Microservices, APIs, Python, System Design, NoSQL (MongoDB), GraphQL, Scalability, Kafka, Redis, CI/CD, Cloud Platforms. Your profile aligns 13% with the role.\n",
      "✅ Final Feedback:\n",
      " ✅ You already have Python, Django, SQL.\n",
      "📌 To improve your profile for Backend Developer, focus on learning: Java, Spring Boot, Docker, Microservices, APIs, System Design, NoSQL (MongoDB), GraphQL, Scalability, Kafka, Redis, CI/CD, Cloud Platforms.\n",
      "📊 Profile Match: 13.33%\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "🔹 Input: Accenture | Data Scientist | ['Numpy', 'TensorFlow', 'SQL', 'Pandas', 'Deep Learning']\n",
      "📝 Raw Model Output: Good foundation in Numpy, TensorFlow, SQL, Pandas, Deep Learning. Still missing Python, SQL, Machine Learning, PyTorch, Statistics, Data Visualization, Feature Engineering, Pandas, Model Deployment, Spark, A/B Testing, Data Cleaning, which are important for this role. Your profile aligns 40% with the role.\n",
      "✅ Final Feedback:\n",
      " ✅ You already have Numpy, TensorFlow, SQL, Pandas, Deep Learning.\n",
      "📌 To improve your profile for Data Scientist, focus on learning: Python, Machine Learning, PyTorch, Statistics, Data Visualization, Feature Engineering, Model Deployment, Spark, A/B Testing, Data Cleaning.\n",
      "📊 Profile Match: 33.33%\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import T5ForConditionalGeneration, T5TokenizerFast\n",
    "import json\n",
    "\n",
    "# ===============================\n",
    "# 🔹 1. Load fine-tuned model\n",
    "# ===============================\n",
    "MODEL_DIR = r\"C:/Users/WIN11/Intelligent-Resume-Feedback-System/src/t5_skill_feedback\"\n",
    "SKILL_DICT_FILE = r\"C:/Users/WIN11/Intelligent-Resume-Feedback-System/data/skill_requirement_dataset.json\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "tokenizer = T5TokenizerFast.from_pretrained(MODEL_DIR)\n",
    "model = T5ForConditionalGeneration.from_pretrained(MODEL_DIR).to(device)\n",
    "\n",
    "# ===============================\n",
    "# 🔹 2. Load skill dictionary JSON\n",
    "# ===============================\n",
    "with open(SKILL_DICT_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "    skill_data = json.load(f)   # <-- directly load array\n",
    "\n",
    "# Convert into role → skills dict\n",
    "skill_dict = {}\n",
    "for company, roles in skill_data.items():\n",
    "    for role, skills in roles.items():\n",
    "        skill_dict[f\"{company}|{role}\"] = skills# ===============================\n",
    "# 🔹 3. Generate raw T5 feedback\n",
    "# ===============================\n",
    "def generate_feedback(company, role, candidate_skills):\n",
    "    input_text = f\"Company: {company} | Role: {role} | Candidate Skills: {', '.join(candidate_skills)}\"\n",
    "    inputs = tokenizer.encode(input_text, return_tensors=\"pt\", truncation=True).to(device)\n",
    "    outputs = model.generate(inputs, max_length=128, num_beams=4, do_sample=True, temperature=0.7)\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "# ===============================\n",
    "# 🔹 4. Post-process feedback\n",
    "# ===============================\n",
    "def post_process_feedback(candidate_skills, role, raw_output):\n",
    "    required_skills = skill_dict.get(f\"{company}|{role}\", [])\n",
    "    cand_set = set([s.lower() for s in candidate_skills])\n",
    "    req_set = set([s.lower() for s in required_skills])\n",
    "\n",
    "    # Missing skills = required - candidate\n",
    "    missing = [s for s in required_skills if s.lower() not in cand_set]\n",
    "\n",
    "    # Compute match %\n",
    "    match_percent = round(len(req_set & cand_set) / len(req_set) * 100, 2) if req_set else 0\n",
    "\n",
    "    # Build clean feedback\n",
    "    feedback = (\n",
    "        f\"✅ You already have {', '.join(candidate_skills)}.\\n\"\n",
    "        f\"📌 To improve your profile for {role}, focus on learning: {', '.join(missing) if missing else 'No extra skills needed!'}.\\n\"\n",
    "        f\"📊 Profile Match: {match_percent}%\"\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"candidate_skills\": candidate_skills,\n",
    "        \"required_skills\": required_skills,\n",
    "        \"missing_skills\": missing,\n",
    "        \"match_percent\": match_percent,\n",
    "        \"raw_output\": raw_output,\n",
    "        \"final_feedback\": feedback\n",
    "    }\n",
    "\n",
    "# ===============================\n",
    "# 🔹 5. Test\n",
    "# ===============================\n",
    "if __name__ == \"__main__\":\n",
    "    tests = [\n",
    "        (\"Google\", \"Data Scientist\", [\"Python\", \"SQL\", \"Pandas\"]),\n",
    "        (\"Microsoft\", \"Backend Developer\", [\"Python\", \"Django\", \"SQL\"]),\n",
    "        (\"Accenture\", \"Data Scientist\", [\"Numpy\", \"TensorFlow\", \"SQL\", \"Pandas\", \"Deep Learning\"]),\n",
    "    ]\n",
    "\n",
    "    for company, role, skills in tests:\n",
    "        raw = generate_feedback(company, role, skills)\n",
    "        result = post_process_feedback(skills, role, raw)\n",
    "\n",
    "        print(\"\\n🔹 Input:\", company, \"|\", role, \"|\", skills)\n",
    "        print(\"📝 Raw Model Output:\", result[\"raw_output\"])\n",
    "        print(\"✅ Final Feedback:\\n\", result[\"final_feedback\"])\n",
    "        print(\"-\" * 80)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
